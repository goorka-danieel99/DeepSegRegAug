# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TeA1pTKBKg0ZzIR3JiAId_sdEjxDN9n7
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os
from sklearn.model_selection import train_test_split

def get_path(path):
  img_path = path + "/img"
  mask_path = path + "/label"

  return img_path, mask_path

def create_dataset(img_path, mask_path):
  img_list = []
  masks_list = []

  for path, current_dic, files in os.walk(img_path):
    for file in files:
      file_path = "/img/" + file
      img_list.append(file_path)

  for path, current_dic, files in os.walk(mask_path):
    for file in files:
      file_path = "/label/" + file
      masks_list.append(file_path)

  img_list.sort()
  masks_list.sort()

  train_img = img_list[:200]
  train_m = masks_list[:200]

  train_images, val_images, train_masks, val_masks = train_test_split(train_img, train_m, test_size=0.15, train_size=0.85)

  test_images = img_list[200:]
  test_masks = masks_list[200:]
  
  return train_images, train_masks, val_images, val_masks, test_images, test_masks

def create_csv(path=path):
  img_path, mask_path = get_path(path)
  train_images, train_masks, val_images, val_masks, test_images, test_masks = create_dataset(img_path, mask_path)

  train_data = {'train_images': train_images, 'train_masks': train_masks} 
  train_df = pd.DataFrame(data=train_data)

  val_data = {'val_images': val_images, 'val_masks': val_masks} 
  val_df = pd.DataFrame(data=val_data)

  test_data = {'test_images': test_images, 'test_masks': test_masks} 
  test_df = pd.DataFrame(data=test_data)

  train_df.to_csv(train_path, index=False)
  val_df.to_csv(val_path, index=False)
  test_df.to_csv(test_path, index=False)