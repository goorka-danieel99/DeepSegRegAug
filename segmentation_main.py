# -*- coding: utf-8 -*-
"""segmentation_main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kwYhlrTM4lif62z0Jjl3UtXjSOhVEm5n
"""

!pip install simpleitk

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
import SimpleITK as sitk
from tqdm import tqdm
import torch.nn as nn
import torch.nn.functional as F

from dataloaders import SegLoader
from models import SegModel
from config import seg_params

# Loading data
train_data = pd.read_csv(seg_params['train_path'])
val_data = pd.read_csv(seg_params['val_path'])


train_images = seg_params['path'] + train_data['train_images'].astype(str)                                     
train_labels = seg_params['path'] + train_data['train_masks'].astype(str)   

val_images = seg_params['path'] + val_data['val_images'].astype(str)   
val_labels = seg_params['path'] + val_data['val_masks'].astype(str)

train_dataset = SegLoader(train_images, train_labels)
val_dataset = SegLoader(val_images, val_labels)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=seg_params['batch_size'], shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=seg_params['batch_size'], shuffle=True)

# Train loop
model = SegModel()
device = torch.device("cuda:0")
model = model.to(device)

criterion = nn.BCEWithLogitsLoss() 

optimizer = torch.optim.Adam(model.parameters())
epochs = seg_params['num_epochs']

training_size = len(train_loader.dataset)
val_size = len(val_loader.dataset)

loss_history = []
val_loss_history = []

best_loss = float("inf")

for epoch in range(epochs):

  train_loss = 0.0
  val_loss = 0.0

  for image, label1, label2 in tqdm(train_loader):
    image = image.to(device)
    label1 = label1.to(device)
    label2 = label2.to(device)

    optimizer.zero_grad()

    pred = model(image)

    loss1 = criterion(pred[:, 0, :, :, :].unsqueeze(1), label1)
    loss2 = criterion(pred[:, 1, :, :, :].unsqueeze(1), label2)

    loss = loss1 + loss2

    loss.backward()
    optimizer.step()

    train_loss += loss.item()

  print('Train Loss', train_loss / training_size)
  loss_history.append(train_loss / training_size)

  for image, label1, label2 in tqdm(val_loader):

    image = image.to(device)
    label1 = label1.to(device)
    label2 = label2.to(device)
    
    pred = model(image)

    loss1 = criterion(pred[:, 0, :, :, :].unsqueeze(1), label1)
    loss2 = criterion(pred[:, 1, :, :, :].unsqueeze(1), label2)

    loss = loss1 + loss2

    val_loss += loss.item()

  print('Val Loss', val_loss / val_size)
  val_loss_history.append(val_loss / val_size)

  if val_loss / val_size < best_loss:
    best_loss = val_loss / val_size

    torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': loss_history,
            'val_loss': val_loss_history,
            }, seg_params['best_loss_path'])

plt.figure()
plt.plot(loss_history, "r-")
plt.plot(val_loss_history, "b-")
plt.grid(True)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(['Train Loss', 'Val Loss'])
plt.show()

# Saving model
torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_loss': loss_history,
        'val_loss': val_loss_history,
        'best_loss': best_loss,
        }, seg_params['seg_model_path'])