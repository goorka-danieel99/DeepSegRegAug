# -*- coding: utf-8 -*-
"""aug_segmentation_main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lVrKWPI9LSlNUazp_0ix0HOryP7oblUm
"""

!pip install simpleitk

!pip install torchio

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import SimpleITK as sitk
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchio as tio
from torch.utils.data import DataLoader
from tqdm import tqdm


import sys
sys.path.insert(0,'/content/drive/MyDrive/Task4/Task4')

from aug_dataloaders import train_list, val_list
from config import config
from models import SegModel
import transforms

# Create train and val tio Subjects Datasets
train_dataset = tio.SubjectsDataset(train_list, transform=transforms_dict['t_nr'])
val_dataset = tio.SubjectsDataset(val_list, transform=transforms_dict['val'])

# Create train and val Datalaoders
training_loader = DataLoader(train_dataset, batch_size=config['seg_batch_size'], shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=config['seg_batch_size'], shuffle=True)

training_size = len(training_loader.dataset)
val_size = len(val_loader.dataset)


# Model init
model = UNet()
device = torch.device("cuda:0")
model = model.to(device)

# Cost function
criterion = nn.BCEWithLogitsLoss() 

# Optimizer
optimizer = torch.optim.Adam(model.parameters(), lr = model_params['learing_rate'], betas = model_params['betas']) ## lr


training_size = len(training_loader.dataset)
val_size = len(val_loader.dataset)

# Lists of train and val losses
loss_history = []
val_loss_history = []

best_loss = float("inf")
writer = tb.SummaryWriter(str(config['runs']) + '/Augmentation_nr')

# Trainloop
for epoch in range(model_params['epochs_seg']):
  train_loss = 0.0
  val_loss = 0.0
  for batch in tqdm(training_loader):
    image = batch['image'][tio.DATA].to(device)
    label1 = batch['mask1'][tio.DATA].to(device)
    label2 = batch['mask2'][tio.DATA].to(device)

    optimizer.zero_grad()

    pred = model(image)

    loss1 = criterion(pred[:, 0, :, :, :].unsqueeze(1), label1)
    loss2 = criterion(pred[:, 1, :, :, :].unsqueeze(1), label2)

    loss = loss1 + loss2

    loss.backward()
    optimizer.step()

    train_loss += loss.item()

  print('Loss/train', train_loss / training_size)
  loss_history.append(train_loss / training_size)


  # Validation
  for batch in tqdm(val_loader):
    image = batch['image'][tio.DATA].to(device)
    label1 = batch['mask1'][tio.DATA].to(device)
    label2 = batch['mask2'][tio.DATA].to(device)

    pred = model(image)

    loss1 = criterion(pred[:, 0, :, :, :].unsqueeze(1), label1)
    loss2 = criterion(pred[:, 1, :, :, :].unsqueeze(1), label2)

    loss = loss1 + loss2
    val_loss += loss.item()

  print('Val Loss', val_loss / val_size)
  val_loss_history.append(val_loss / val_size)

  # Tensorboard
  writer.add_scalars(f'LOSS/aug_nr', {
            'Training': train_loss,
            'Val': val_loss,
            }, global_step = epoch)

  # Saving model with best val loss
  if val_loss / val_size < best_loss:
    best_loss = val_loss / val_size

    torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': loss_history,
            'val_loss': val_loss_history,
            'best_loss': best_loss,
            }, best_path)
  
  # Saving model every n epoch
  if epoch % model_params['epoch_save']==0:
    torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': loss_history,
            'val_loss': val_loss_history,
            'best_loss': best_loss,
            }, epoch_path)