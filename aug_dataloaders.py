# -*- coding: utf-8 -*-
"""dataloaders.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sZR0z39-WG-Z5jlpO7J-RVdnP-_XwHtA
"""

import torch
import torchio as tio
import SimpleITK as sitk
import pandas as pd
import numpy as np
from config import config


# Loading images
train_dataset = pd.read_csv(config['train_dataset'])
val_dataset = pd.read_csv(config['val_dataset'])

path = 'path'

train_images = path + train_dataset["train_images"]
train_masks = path + train_dataset["train_masks"]

val_images = path + val_dataset["val_images"]
val_masks = path + val_dataset["val_masks"]

# Functions for separating masks
def mask1_tensor(path):
  mask = sitk.GetArrayFromImage(sitk.ReadImage(path))
  mask1 = mask == 1
  mask1_tensor = torch.from_numpy(mask1.astype(np.float32))[:,:,:].unsqueeze(0).permute(0,3,2,1)
  return mask1_tensor

def mask2_tensor(path):
  mask = sitk.GetArrayFromImage(sitk.ReadImage(path))
  mask2 = mask == 2
  mask2_tensor = torch.from_numpy(mask2.astype(np.float32))[:,:,:].unsqueeze(0).permute(0,3,2,1)
  return mask2_tensor

# ------------------- TorchIO subjects for segmentation ----------------------
train_list = []
for i in range(len(train_images)):

  image = train_images[i]
  mask = train_masks[i]

  subject = tio.Subject(
      image = tio.ScalarImage(image),
      mask1 = tio.LabelMap(tensor=mask1_tensor(mask)),
      mask2 = tio.LabelMap(tensor=mask2_tensor(mask)),
  )
  train_list.append(subject)


val_list = []
for i in range(len(val_images)):
  image = val_images[i]
  mask = val_masks[i]

  subject = tio.Subject(
      image = tio.ScalarImage(image),
      mask1 = tio.LabelMap(tensor=mask1_tensor(mask)),
      mask2 = tio.LabelMap(tensor=mask2_tensor(mask)),  
  )
  val_list.append(subject)


# ------------------- TorchIO subjects for registration ----------------------
fixed_images = train_images
moving_images = train_images

val_fixed_images = val_images
val_moving_images = val_images

val_fixed_masks = val_masks
val_moving_masks = val_masks


fixed_list = []
moving_list = []

train_pairs_reg = []
for fixed in fixed_images:
    for moving in moving_images:
        if fixed != moving:
            imagef = fixed
            imagem = moving

            subject = tio.Subject(
                imagef = tio.ScalarImage(imagef), 
                imagem = tio.ScalarImage(imagem),
            )
            train_pairs_reg.append(subject)

train_pairs_reg = random.sample(train_pairs_reg, 500)

val_pairs_reg = []
for val_fixed, val_fixed_mask in zip(val_fixed_images,val_fixed_masks):
    for val_moving, val_moving_mask in zip(val_moving_images, val_moving_masks):
        if val_fixed != val_moving and val_fixed_mask != val_moving_mask:
            imagef = val_fixed
            maskf = val_fixed_mask

            imagem = '/net/archive/groups/plggaug/data/Training/' + val_moving
            maskm = '/net/archive/groups/plggaug/data/Training/' + val_moving_mask

            subject = tio.Subject(
                imagef = tio.ScalarImage(imagef), 
                maskf1 = tio.LabelMap(tensor=mask1_tensor(maskf)),
                maskf2 = tio.LabelMap(tensor=mask2_tensor(maskf)),

                imagem = tio.ScalarImage(imagem),
                maskm1 = tio.LabelMap(tensor=mask1_tensor(maskm)),
                maskm2 = tio.LabelMap(tensor=mask2_tensor(maskm)),
            )
            val_pairs_reg.append(subject)